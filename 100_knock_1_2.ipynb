{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "05"
      ],
      "metadata": {
        "id": "0grEEC4tdfsY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgVkq5h_dYKH",
        "outputId": "1c2fd10f-f0ef-4fd6-d653-1f53c3a39a25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "単語bi_gram： [['I', 'am'], ['am', 'an'], ['an', 'NLPer']]\n",
            "文字bi_gram： ['Ia', 'am', 'ma', 'an', 'nN', 'NL', 'LP', 'Pe', 'er']\n"
          ]
        }
      ],
      "source": [
        "def n_gram(n, list):\n",
        "  n_gram = []\n",
        "  for i in range(len(list)-n+1):\n",
        "    n_gram.append(list[i:i+n])\n",
        "\n",
        "  return n_gram\n",
        "\n",
        "text = \"I am an NLPer\"\n",
        "\n",
        "word_list = text.split()\n",
        "char_list = text.replace(\" \", \"\")\n",
        "\n",
        "w_n_gram = n_gram(2, word_list)\n",
        "c_n_gram = n_gram(2, char_list)\n",
        "print(\"単語bi_gram：\", w_n_gram)\n",
        "print(\"文字bi_gram：\", c_n_gram)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "06"
      ],
      "metadata": {
        "id": "Pz7btAJPdjgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text06_1 = \"paraparaparadise\"\n",
        "text06_2 = \"paragraph\"\n",
        "\n",
        "_, x_list = n_gram(2, text06_1)\n",
        "_, y_list = n_gram(2, text06_2)\n",
        "\n",
        "X = set(x_list)\n",
        "Y = set(y_list)\n",
        "\n",
        "\n",
        "print(\"和集合：\", X | Y)\n",
        "print(\"積集合：\", X & Y)\n",
        "print(\"差集合：\", X - Y)\n",
        "\n",
        "check = \"se\"\n",
        "if (check in X) and (check in Y):\n",
        "  print(check + \"はXとYに含まれる\")\n",
        "elif check in X:\n",
        "  print(check + \"はXに含まれる\")\n",
        "elif check in Y:\n",
        "  print(check + \"はYに含まれる\")\n",
        "else:\n",
        "  print(check + \"はXとYには含まれない\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1d6Pud7de2r",
        "outputId": "c0e59752-6b66-4157-eb6c-3b815478e5ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "和集合： {'pa', 'di', 'se', 'gr', 'ph', 'ar', 'ad', 'ap', 'is', 'ag', 'ra'}\n",
            "積集合： {'ra', 'ar', 'ap', 'pa'}\n",
            "差集合： {'di', 'is', 'ad', 'se'}\n",
            "seはXに含まれる\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "07"
      ],
      "metadata": {
        "id": "gcDun43ZtEyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_generate(x, y, z):\n",
        "    temp = str(x) + \"時の\" + y + \"は\" + str(z)\n",
        "    return temp\n",
        "\n",
        "\n",
        "text = text_generate(12, \"気温\", 22.4)\n",
        "print(text)"
      ],
      "metadata": {
        "id": "_JKvyyAatEEZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5a64473-4a5a-4974-a790-70fd95c8b9c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12時の気温は22.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "08"
      ],
      "metadata": {
        "id": "7Uugv9CvTes-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def cipher(text):\n",
        "  temp = \"\"\n",
        "  for ch in text:\n",
        "    if re.match('[a-z]', ch):\n",
        "      ch = chr(219 - ord(ch))\n",
        "    temp += ch\n",
        "  return temp\n",
        "\n",
        "en_text = cipher(\"Hello world!!\")\n",
        "print(en_text)\n",
        "de_text = cipher(en_text)\n",
        "print(de_text)"
      ],
      "metadata": {
        "id": "lLuBZomETeXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd24d60f-b548-4627-a491-9188e8abe5c2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hvool dliow!!\n",
            "Hello world!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "09"
      ],
      "metadata": {
        "id": "gB7Av140k8mm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "text = \"I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n",
        "split_text = text.split()\n",
        "sort_text = \"\"\n",
        "for word in split_text:\n",
        "    if len(word) >= 4:\n",
        "        word = word[0]+\"\".join(random.sample(word[1:-1], len(word[1:-1])))+word[-1]\n",
        "    else:\n",
        "        pass\n",
        "    sort_text += word + \" \"\n",
        "print(sort_text)\n"
      ],
      "metadata": {
        "id": "NGD2g-tCTbpe",
        "outputId": "db47974a-35da-4808-f3f3-0d4e9a11d714",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I cl’dnuot bleveie that I cuold alcltauy ueannsdtrd waht I was radeing : the pmeeonhnal pwoer of the hmaun mind . \n"
          ]
        }
      ]
    }
  ]
}